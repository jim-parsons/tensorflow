{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 3)\n",
      "(47, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def normalize_feature(df):\n",
    "    return df.apply(lambda col: (col - col.mean()) / col.std())\n",
    "\n",
    "df = normalize_feature(pd.read_csv('data1.csv', names=['square', 'bedrooms', 'price']))\n",
    "df.head()\n",
    "ones =  pd.DataFrame({'ones': np.ones(len(df))})\n",
    "df = pd.concat([ones, df], axis=1)\n",
    "X_data = np.array(df[df.columns[:3]])\n",
    "Y_data = np.array(df[df.columns[-1]]).reshape(len(df), 1)\n",
    "\n",
    "print(X_data.shape)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\enmonster\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import VariableAggregation\n",
    "\n",
    "alpha = 0.01\n",
    "epoch = 500\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, X_data.shape)\n",
    "    Y = tf.placeholder(tf.float32, Y_data.shape)\n",
    "\n",
    "# W = tf.get_variable('weights', (X_data.shape[1], 1), initializer=tf.constant_initializer())\n",
    "#with tf.variable_scope('weights', reuse=tf.AUTO_REUSE):\n",
    "with tf.name_scope('hype'):\n",
    "    W = tf.get_variable(\"weights\", (X_data.shape[1], 1), initializer=tf.constant_initializer())\n",
    "\n",
    "    y_pred = tf.matmul(X, W)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    #loss_op = 1 / (2 * len(X_data)) * tf.matmul((y_pred - Y), (y_pred - Y), transpose_a=True)\n",
    "    loss_op = tf.reduce_mean(tf.square(y_pred - Y))\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate=alpha).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 \t Loss=0.7046 \t Model: y = 0.1497x1 + 0.072x2 + 1.863e-11\n",
      "Epoch 20 \t Loss=0.5481 \t Model: y = 0.2667x1 + 0.1177x2 + 4.284e-10\n",
      "Epoch 30 \t Loss=0.4562 \t Model: y = 0.359x1 + 0.1446x2 + -3.725e-11\n",
      "Epoch 40 \t Loss=0.4004 \t Model: y = 0.4327x1 + 0.1583x2 + -9.313e-12\n",
      "Epoch 50 \t Loss=0.3649 \t Model: y = 0.4923x1 + 0.1629x2 + 6.426e-10\n",
      "Epoch 60 \t Loss=0.3412 \t Model: y = 0.541x1 + 0.1612x2 + 1.257e-09\n",
      "Epoch 70 \t Loss=0.3247 \t Model: y = 0.5814x1 + 0.1553x2 + 1.639e-09\n",
      "Epoch 80 \t Loss=0.3125 \t Model: y = 0.6152x1 + 0.1468x2 + 1.127e-09\n",
      "Epoch 90 \t Loss=0.3033 \t Model: y = 0.644x1 + 0.1366x2 + 1.495e-09\n",
      "Epoch 100 \t Loss=0.296 \t Model: y = 0.6686x1 + 0.1256x2 + 7.218e-10\n",
      "Epoch 110 \t Loss=0.2902 \t Model: y = 0.69x1 + 0.1142x2 + 1.35e-09\n",
      "Epoch 120 \t Loss=0.2854 \t Model: y = 0.7086x1 + 0.1028x2 + 1.718e-09\n",
      "Epoch 130 \t Loss=0.2815 \t Model: y = 0.7251x1 + 0.09176x2 + 1.017e-09\n",
      "Epoch 140 \t Loss=0.2783 \t Model: y = 0.7397x1 + 0.0811x2 + 1.574e-09\n",
      "Epoch 150 \t Loss=0.2756 \t Model: y = 0.7527x1 + 0.07097x2 + 1.485e-09\n",
      "Epoch 160 \t Loss=0.2733 \t Model: y = 0.7644x1 + 0.06141x2 + 9.954e-10\n",
      "Epoch 170 \t Loss=0.2714 \t Model: y = 0.7749x1 + 0.05245x2 + 1.591e-09\n",
      "Epoch 180 \t Loss=0.2698 \t Model: y = 0.7844x1 + 0.04409x2 + 1.827e-09\n",
      "Epoch 190 \t Loss=0.2685 \t Model: y = 0.793x1 + 0.03631x2 + 1.799e-09\n",
      "Epoch 200 \t Loss=0.2673 \t Model: y = 0.8008x1 + 0.02911x2 + 1.787e-09\n",
      "Epoch 210 \t Loss=0.2664 \t Model: y = 0.8079x1 + 0.02244x2 + 1.798e-09\n",
      "Epoch 220 \t Loss=0.2656 \t Model: y = 0.8144x1 + 0.01629x2 + 2.197e-09\n",
      "Epoch 230 \t Loss=0.2649 \t Model: y = 0.8203x1 + 0.01062x2 + 1.808e-09\n",
      "Epoch 240 \t Loss=0.2644 \t Model: y = 0.8257x1 + 0.005391x2 + 1.935e-09\n",
      "Epoch 250 \t Loss=0.2639 \t Model: y = 0.8306x1 + 0.0005822x2 + 2.173e-09\n",
      "Epoch 260 \t Loss=0.2635 \t Model: y = 0.8352x1 + -0.00384x2 + 2.516e-09\n",
      "Epoch 270 \t Loss=0.2631 \t Model: y = 0.8393x1 + -0.007905x2 + 2.996e-09\n",
      "Epoch 280 \t Loss=0.2629 \t Model: y = 0.8431x1 + -0.01164x2 + 3.24e-09\n",
      "Epoch 290 \t Loss=0.2626 \t Model: y = 0.8466x1 + -0.01507x2 + 3.587e-09\n",
      "Epoch 300 \t Loss=0.2624 \t Model: y = 0.8497x1 + -0.01822x2 + 3.065e-09\n",
      "Epoch 310 \t Loss=0.2623 \t Model: y = 0.8526x1 + -0.02111x2 + 3.298e-09\n",
      "Epoch 320 \t Loss=0.2621 \t Model: y = 0.8553x1 + -0.02376x2 + 3.42e-09\n",
      "Epoch 330 \t Loss=0.262 \t Model: y = 0.8578x1 + -0.02619x2 + 3.588e-09\n",
      "Epoch 340 \t Loss=0.2619 \t Model: y = 0.86x1 + -0.02843x2 + 4.277e-09\n",
      "Epoch 350 \t Loss=0.2618 \t Model: y = 0.862x1 + -0.03048x2 + 4.603e-09\n",
      "Epoch 360 \t Loss=0.2617 \t Model: y = 0.8639x1 + -0.03236x2 + 4.366e-09\n",
      "Epoch 370 \t Loss=0.2617 \t Model: y = 0.8657x1 + -0.03408x2 + 5.299e-09\n",
      "Epoch 380 \t Loss=0.2616 \t Model: y = 0.8672x1 + -0.03566x2 + 4.824e-09\n",
      "Epoch 390 \t Loss=0.2616 \t Model: y = 0.8687x1 + -0.03711x2 + 4.566e-09\n",
      "Epoch 400 \t Loss=0.2616 \t Model: y = 0.87x1 + -0.03845x2 + 4.834e-09\n",
      "Epoch 410 \t Loss=0.2615 \t Model: y = 0.8713x1 + -0.03967x2 + 4.689e-09\n",
      "Epoch 420 \t Loss=0.2615 \t Model: y = 0.8724x1 + -0.04079x2 + 4.987e-09\n",
      "Epoch 430 \t Loss=0.2615 \t Model: y = 0.8734x1 + -0.04181x2 + 5.686e-09\n",
      "Epoch 440 \t Loss=0.2615 \t Model: y = 0.8743x1 + -0.04275x2 + 5.6e-09\n",
      "Epoch 450 \t Loss=0.2615 \t Model: y = 0.8752x1 + -0.04362x2 + 5.63e-09\n",
      "Epoch 460 \t Loss=0.2614 \t Model: y = 0.876x1 + -0.04441x2 + 6.515e-09\n",
      "Epoch 470 \t Loss=0.2614 \t Model: y = 0.8767x1 + -0.04514x2 + 6.37e-09\n",
      "Epoch 480 \t Loss=0.2614 \t Model: y = 0.8774x1 + -0.0458x2 + 6.806e-09\n",
      "Epoch 490 \t Loss=0.2614 \t Model: y = 0.878x1 + -0.04641x2 + 6.815e-09\n",
      "Epoch 500 \t Loss=0.2614 \t Model: y = 0.8786x1 + -0.04698x2 + 7.227e-09\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./summary/linear-regression-1', sess.graph)\n",
    "    for e in range(1, epoch + 1):\n",
    "        sess.run(train_op, feed_dict={X: X_data, Y: Y_data})\n",
    "        if e % 10 == 0:\n",
    "            loss, w = sess.run([loss_op, W], feed_dict={X: X_data, Y: Y_data})\n",
    "            log_str = \"Epoch %d \\t Loss=%.4g \\t Model: y = %.4gx1 + %.4gx2 + %.4g\"\n",
    "            print(log_str % (e, loss, w[1], w[2], w[0]))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
