{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import datasets\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kearas 支持channel first和channel last\n",
    "# channel first: [batch, channel, height, width]\n",
    "# channel last: [batch, height, width, channel]  默认\n",
    "# 可以在./keras/keras.json 进行配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() ==  'channel_first':\n",
    "    x_train  = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) # 1为通道数\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train  = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) # 1为通道数\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.astype('float32')\n",
    "X_test = x_test.astype('float32')\n",
    "# 数据归一化\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding befor: (60000,)\n",
      "one-hot encoding after: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "n_classes = 10\n",
    "print(\"one-hot encoding befor:\", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "print(\"one-hot encoding after:\", Y_train.shape)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\enmonster\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:3138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "## feature extraction\n",
    "# 第一层卷积， 32个3X3卷积核，激活函数relu\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) # input_shape [28, 28, 1]\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 查看模型结构\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 26, 26, 32]\n",
      "[None, 24, 24, 64]\n",
      "[None, 12, 12, 64]\n",
      "[None, 12, 12, 64]\n",
      "[None, None]\n",
      "[None, 128]\n",
      "[None, 128]\n",
      "[None, 10]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.get_output_at(0).get_shape().as_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\enmonster\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      " - 108s - loss: 0.2252 - acc: 0.9319 - val_loss: 0.0488 - val_acc: 0.9833\n",
      "Epoch 2/5\n",
      " - 106s - loss: 0.0815 - acc: 0.9757 - val_loss: 0.0371 - val_acc: 0.9868\n",
      "Epoch 3/5\n",
      " - 114s - loss: 0.0592 - acc: 0.9820 - val_loss: 0.0291 - val_acc: 0.9897\n",
      "Epoch 4/5\n",
      " - 107s - loss: 0.0509 - acc: 0.9847 - val_loss: 0.0308 - val_acc: 0.9893\n",
      "Epoch 5/5\n",
      " - 106s - loss: 0.0424 - acc: 0.9869 - val_loss: 0.0303 - val_acc: 0.9894\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=5, verbose=2, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved as path ./mnist/model/keras_mnist.h5\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "import os\n",
    "import tensorflow.gfile as gfile\n",
    "\n",
    "save_dir = './mnist/model/'\n",
    "\n",
    "if gfile.Exists(save_dir):\n",
    "    gfile.DeleteRecursively(save_dir)\n",
    "gfile.MakeDirs(save_dir)\n",
    "\n",
    "model_name = 'keras_mnist.h5'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('model saved as path {}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.030295624294431764\n",
      "Test Accuracy: 98.94%\n",
      "Classified correctly count: 9894\n",
      "Classified incorrectly count: 106\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "mnist_model = load_model(model_path)\n",
    "\n",
    "# 统计模型在测试集的分类结果\n",
    "\n",
    "loss_and_metrics = mnist_model.evaluate(X_test, Y_test, verbose=2)\n",
    "\n",
    "print(\"Test Loss: {}\".format(loss_and_metrics[0]))\n",
    "print(\"Test Accuracy: {}%\".format(loss_and_metrics[1]*100))\n",
    "\n",
    "predicted_classes = mnist_model.predict_classes(X_test)\n",
    "\n",
    "correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != y_test)[0]\n",
    "\n",
    "print(\"Classified correctly count: {}\".format(len(correct_indices)))\n",
    "print(\"Classified incorrectly count: {}\".format(len(incorrect_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
